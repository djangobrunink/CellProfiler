{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai2.vision.all import *\n",
    "import typing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pycocotools.mask as mask_util\n",
    "import matplotlib.patches as patches\n",
    "import functools\n",
    "import detection.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"../dataset\")\n",
    "annotations_path = dataset_root / \"via_region_data_fish_type.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(annotations_path) as f:\n",
    "    annotations_data = list(json.load(f).values())\n",
    "annotations_data_train, annotations_data_test = train_test_split(annotations_data, test_size=0.25)\n",
    "len(annotations_data_train), len(annotations_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_to_bitmask(polygons: typing.List[np.ndarray], height: int, width: int) -> np.ndarray:\n",
    "    assert len(polygons) > 0, \"COCOAPI does not support empty polygons\"\n",
    "    rles = mask_util.frPyObjects(polygons, height, width)\n",
    "    rle = mask_util.merge(rles)\n",
    "    return mask_util.decode(rle).astype(np.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FishDataset(object):\n",
    "    def __init__(self, root, annotations_data, transforms = None):\n",
    "        self.root = root\n",
    "        self.annotations_data = list(annotations_data)\n",
    "        self.transforms = transforms\n",
    "        self.n_inp = 1\n",
    "\n",
    "\n",
    "       \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image, target = self._get(index)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "        \n",
    "        return image, target\n",
    "        \n",
    "    @functools.lru_cache(1000)\n",
    "    def _get(self, index):\n",
    "        data = self.annotations_data[index]\n",
    "        file_path = data[\"filename\"]\n",
    "        image = Image.open(self.root / file_path).convert(\"RGB\")\n",
    "        \n",
    "        boxes = []\n",
    "        polygons = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        \n",
    "        for region in data[\"regions\"]:\n",
    "            shape_attributes = region[\"shape_attributes\"]\n",
    "            px = shape_attributes[\"all_points_x\"]\n",
    "            py = shape_attributes[\"all_points_y\"]\n",
    "            \n",
    "            poly = [[x, y] for x, y in zip(px, py)]\n",
    "            poly = [list(itertools.chain.from_iterable(poly))]\n",
    "            mask = np.uint8(polygons_to_bitmask(poly, image.height, image.width))\n",
    "            \n",
    "            box = [min(px), min(py), max(px), max(py)]\n",
    "            \n",
    "            category_id = 1 #TODO\n",
    "            \n",
    "            boxes.append(box)\n",
    "            masks.append(mask)\n",
    "            labels.append(category_id)\n",
    "           \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        image_id =  torch.tensor([index])\n",
    "    \n",
    "        areas = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"masks\": masks,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": areas,\n",
    "            \"iscrowd\": torch.zeros((len(labels),), dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_item(image, target):\n",
    "    image = np.array(image)\n",
    "    print(image.shape)\n",
    "    \n",
    "\n",
    "    ax = plt.axes()\n",
    "    ax.imshow(image)\n",
    "    \n",
    "\n",
    "    for xmin, ymin, xmax, ymax in target[\"boxes\"]:\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "    draw_mask = np.zeros(target[\"masks\"][0].shape)\n",
    "    for mask in target[\"masks\"]:\n",
    "        mask = np.array(mask)\n",
    "        draw_mask += mask\n",
    "    \n",
    "    plt.imshow(draw_mask > 0, 'gray', interpolation='none', alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detection.transforms as T\n",
    "\n",
    "def get_transform():\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    #if train:\n",
    "    #    transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    \n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "def create_model(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels \n",
    "    hidden_layer = 256\n",
    "\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(\n",
    "        in_features_mask,\n",
    "        hidden_layer,\n",
    "        num_classes,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_splitter(model):\n",
    "    return [params(model.backbone), params(model.rpn), params(model.roi_heads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FishDataset(dataset_root, annotations_data_train,  get_transform())\n",
    "valid_ds = FishDataset(dataset_root, annotations_data_test,  get_transform())\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=4, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    collate_fn=utils.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jordi/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:2854: UserWarning: The default behavior for interpolate/upsample with float scale_factor will change in 1.6.0 to align with other frameworks/libraries, and use scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor will change \"\n",
      "/opt/conda/conda-bld/pytorch_1591914858187/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9331, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.4563484775012443e-07 1\n",
      "tensor(6.4633, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "2.1209508879201927e-07 2\n",
      "tensor(5.7778, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "3.0888435964774783e-07 3\n",
      "tensor(5.9343, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "4.498432668969444e-07 4\n",
      "tensor(6.0961, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "6.55128556859551e-07 5\n",
      "tensor(6.0877, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "9.540954763499944e-07 6\n",
      "tensor(5.7725, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.389495494373136e-06 7\n",
      "tensor(5.1417, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "2.0235896477251557e-06 8\n",
      "tensor(5.6835, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "2.94705170255181e-06 9\n",
      "tensor(5.8673, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "4.291934260128778e-06 10\n",
      "tensor(5.3107, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "6.250551925273976e-06 11\n",
      "tensor(5.8012, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "9.102981779915228e-06 12\n",
      "tensor(4.5768, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.3257113655901082e-05 13\n",
      "tensor(4.5595, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.9306977288832496e-05 14\n",
      "tensor(4.7889, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "2.8117686979742253e-05 15\n",
      "tensor(3.6233, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "4.094915062380419e-05 16\n",
      "tensor(3.1891, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "5.9636233165946365e-05 17\n",
      "tensor(2.9790, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "8.68511373751352e-05 18\n",
      "tensor(2.1244, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.00012648552168552957 19\n",
      "tensor(1.6883, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.00018420699693267144 20\n",
      "tensor(1.4507, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.00026826957952797245 21\n",
      "tensor(1.8465, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0003906939937054613 22\n",
      "tensor(1.4455, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0005689866029018293 23\n",
      "tensor(1.1808, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0008286427728546842 24\n",
      "tensor(1.2248, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0012067926406393288 25\n",
      "tensor(1.2506, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0017575106248547893 26\n",
      "tensor(2.2067, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.0025595479226995332 27\n",
      "tensor(20.3134, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.003727593720314938 28\n",
      "tensor(1.5639, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.005428675439323859 29\n",
      "tensor(3.0833, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.007906043210907685 30\n",
      "tensor(3.9520, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.011513953993264457 31\n",
      "tensor(4.6208, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.016768329368110065 32\n",
      "tensor(3.5453, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.024420530945486497 33\n",
      "tensor(4.7167, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.03556480306223128 34\n",
      "tensor(3.2996, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.05179474679231202 35\n",
      "tensor(14.7564, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.07543120063354607 36\n",
      "tensor(18.4179, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.10985411419875572 37\n",
      "tensor(232.0828, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.15998587196060574 38\n",
      "tensor(88.2041, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.23299518105153671 39\n",
      "tensor(3266.7988, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.3393221771895323 40\n",
      "tensor(6950.5137, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.4941713361323828 41\n",
      "tensor(10028.6680, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "0.7196856730011514 42\n",
      "tensor(14527.8164, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.0481131341546852 43\n",
      "tensor(1677295.8750, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "1.5264179671752303 44\n",
      "tensor(430945.5000, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "2.222996482526191 45\n",
      "tensor(1110096.1250, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "3.2374575428176398 46\n",
      "tensor(20337720., device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "4.714866363457389 47\n",
      "tensor(70626968., device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "6.866488450042998 48\n",
      "tensor(3.9680e+08, device='cuda:0', grad_fn=<AddBackward0>) True\n",
      "10.0 49\n",
      "tensor(3.2862e+08, device='cuda:0', grad_fn=<AddBackward0>) True\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-af262e17d436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH_DEPRECATION_WARNING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mget_lr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m                           \"please use `get_last_lr()`.\")\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         return [base_lr * lmbda(self.last_epoch)\n\u001b[0m\u001b[1;32m    235\u001b[0m                 for lmbda, base_lr in zip(self.lr_lambdas, self.base_lrs)]\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    232\u001b[0m                           \"please use `get_last_lr()`.\")\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         return [base_lr * lmbda(self.last_epoch)\n\u001b[0m\u001b[1;32m    235\u001b[0m                 for lmbda, base_lr in zip(self.lr_lambdas, self.base_lrs)]\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-af262e17d436>\u001b[0m in \u001b[0;36mlambda_\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mlr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambdaLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 50 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "parameter_groups = params_splitter(model)\n",
    "for o in parameter_groups[0] + parameter_groups[1]:\n",
    "    o.requires_grad = False\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\"\"\"\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, \n",
    "    lr=1,\n",
    "    momentum=0.9, \n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\"\"\"\n",
    "optimizer = torch.optim.Adam(params, lr=1)\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "start_lr=1e-7\n",
    "end_lr=10\n",
    "\n",
    "lrs = np.logspace(np.log10(start_lr), np.log10(end_lr))\n",
    "def lambda_(epoch):\n",
    "    print(lrs[epoch], epoch)\n",
    "    return lrs[epoch]\n",
    "lr_scheduler = LambdaLR(optimizer, lambda_)\n",
    "\n",
    "\n",
    "model.train()\n",
    "loss = []\n",
    "\n",
    "i = 0\n",
    "while i < len(lrs):\n",
    "    for images, targets in data_loader:\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        print(losses, math.isfinite(losses))\n",
    "        \n",
    "        if not math.isfinite(losses):\n",
    "            i = len(lrs)\n",
    "            break\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if len(loss) == 0:\n",
    "            loss.append(losses)\n",
    "        else:\n",
    "            loss.append(0.9 * loss[-1] + 0.1 * losses)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i >= len(lrs):\n",
    "            break\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.93306828e+00, 5.98609400e+00, 5.96526241e+00, 5.96216774e+00,\n",
       "       5.97556162e+00, 5.98678064e+00, 5.96535015e+00, 5.88298702e+00,\n",
       "       5.86303711e+00, 5.86346006e+00, 5.80817938e+00, 5.80748224e+00,\n",
       "       5.68441105e+00, 5.57192087e+00, 5.49361849e+00, 5.30658579e+00,\n",
       "       5.09484148e+00, 4.88325882e+00, 4.60737753e+00, 4.31546593e+00,\n",
       "       4.02899170e+00, 3.81074500e+00, 3.57421541e+00, 3.33487391e+00,\n",
       "       3.12386322e+00, 2.93653512e+00, 2.86355305e+00, 4.60853863e+00,\n",
       "       4.30407572e+00, 4.18199730e+00, 4.15900183e+00, 4.20518494e+00,\n",
       "       4.13919163e+00, 4.19693851e+00, 4.10720301e+00, 5.17212391e+00,\n",
       "       6.49669838e+00, 2.90553093e+01, 3.49701843e+01, 3.58153076e+02,\n",
       "       1.01738916e+03, 1.91851709e+03, 3.17944678e+03, 1.70591094e+05,\n",
       "       1.96626531e+05, 2.87973500e+05, 2.29294825e+06, 9.12635000e+06,\n",
       "       4.78933760e+07], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = np.array([l.cpu().detach().numpy() for l in loss])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss), len(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.9330683, 5.986094 , 5.9652624, 5.9621677, 5.9755616, 5.9867806,\n",
       "       5.96535  , 5.882987 , 5.863037 , 5.86346  , 5.8081794, 5.8074822,\n",
       "       5.684411 , 5.571921 , 5.4936185, 5.306586 , 5.0948415, 4.883259 ,\n",
       "       4.6073775, 4.315466 , 4.0289917, 3.810745 , 3.5742154, 3.334874 ,\n",
       "       3.1238632, 2.9365351, 2.863553 , 4.6085386, 4.3040757, 4.1819973,\n",
       "       4.159002 , 4.205185 , 4.1391916, 4.1969385, 4.107203 , 5.172124 ,\n",
       "       6.4966984], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2 = loss[loss < 5 * np.min(loss)]\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017575106248547893\n",
      "0.00017575106248547893\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU5dn48e89ySQhO1nYshD2fTUiiFJERQRa19eibe3ir5Si2EVf3Lra17elfV2xlSK21bq1olJURKWKSBE1LEFkJwQIYckEErKvz++PTDCEhEySmTlzJvfnuubizDnPnHM/THLnzDPPIsYYlFJKBReH1QEopZTyPk3uSikVhDS5K6VUENLkrpRSQUiTu1JKBSFN7kopFYRCrbpwUlKSycjIsOrySillS5s2bXIZY5LbKmdZcs/IyCArK8uqyyullC2JyEFPymmzjFJKBSFN7kopFYQ0uSulVBDS5K6UUkHIo+QuIvEislxEdonIThGZ1Oz4VBEpFpGt7scvfBOuUkopT3jaW+ZxYLUx5kYRCQMiWyjzkTFmtvdCU0op1VFt3rmLSCwwBXgGwBhTbYwp8nVgSikVjN794hj7C0p9fh1PmmX6AwXAX0Vki4gsE5GoFspNEpFsEXlbREa0dCIRmSsiWSKSVVBQ0Jm4lVLKdurrDbe/uJnlm/J8fi1PknsoMB54yhgzDigD7m1WZjPQ1xgzBlgMrGjpRMaYpcaYTGNMZnJymwOslFIqqLhKq6ipM/SJ7+bza3mS3POAPGPMJ+7ny2lI9mcYY04bY0rd26sAp4gkeTVSpZSyuSNFFQCkxEf4/FptJndjzDHgsIgMce+6HNjRtIyI9BIRcW9PcJ+30MuxKqWUreUXVQL45c7d094yC4AX3D1lcoDvisg8AGPMEuBG4IciUgtUAHOMLs6qlFJnyXffuQdMcjfGbAUym+1e0uT4k8CTXoxLKaWCzpGiCmLCQ4mNcPr8WjpCVSml/CS/qMIvd+2gyV0ppfwmv7iCPn74MhU0uSullN/kF1XqnbtSSgWT8upaTpZVa3JXSqlg0tgNMkWTu1JKBQ9/doMETe5KKeUXXyZ3/UJVKaWCRn5RBQ6BnrGa3JVSKmgcKaqkZ2wEzhD/pF1N7kop5Qf+HMAEmtyVUsovGgYwaXJXSqmgUV9vOFpU6bcvU0GTu1JK+ZyrrIrqunpS9c5dKaWChz/ncW+kyV0ppXzM3wOYQJO7Ukr5nCZ3pZQKQkeKKogODyU2wtPF7zpPk7tSSvlYQx/3CNxLTfuFR8ldROJFZLmI7BKRnSIyqdlxEZEnRGSfiGwTkfG+CVcppezHn/O4N/L0zv1xYLUxZigwBtjZ7PjVwCD3Yy7wlNciVEopm/P36FTwILmLSCwwBXgGwBhTbYwpalbsGuA502AjEC8ivb0erVJK2UxlTR2FZdV+m8e9kSet+/2BAuCvIjIG2AT8yBhT1qRMCnC4yfM8976jTU8kInNpuLMnPT29E2G37mhxBe9sP0Z1XT3pCVGkJ0SSnhhJdLj3v8gwxlBeXcep8mqKymsoKq9p2K6ooaismtOVNSRGh9M3IZK+iVH0TYwkygdxKKUCl7+n+m3kSaYJBcYDC4wxn4jI48C9wM+blGnpWwJzzg5jlgJLATIzM8853lEnSip5+/NjvLktn89yT7VYJjEqjLSESPomRpKeEEnvuG6EhTpwhgihDgehIXJm2xnS8Ly0shZXaRWFZdUUllZRWFqNq6waV0kVhWVVnCqrobquvtW4wkMdVNWefTwpOoz0hEgyEqNIT4xkXHp3pgxK8usXLUop/zkzgCku8O7c84A8Y8wn7ufLaUjuzcukNXmeCuR3PrzWnSyrZvX2hoS+MaeQegODe0Zz15WDmTW6N4lR4Rw6Wc6hk+UcPFnGYff25kOneCM7n/p2/mmJcDpIig4nMTqc3nERjEyJJSEqnO6RTuIjncRHhhHfzUn3qIZ/4yKdhIeGcLqyhkOF5RwsbIjjoKvh3405hby+9QjGwLj0eBZeNZRJAxJ985+llLKMFX3cwYPkbow5JiKHRWSIMWY3cDmwo1mxlcAdIvIycBFQbIw52vxc3rDp4Cme+Pde1u9zUVdv6JcUxR2XDWT2mD4M7hlzVtlRkXGMSo075xw1dfW4SquoqTXU1NdTW2eoqauntt5QW1dPdV09dfWG6PBQd0IPIzKsY80psRFORqbEMTLl3Dgqa+pYseUIj63Zy81Pb2TK4GQWXjWkxbJKKXs6UlSBCPSKC7xmGYAFwAsiEgbkAN8VkXkAxpglwCpgJrAPKAe+64NYgYbEvL+glO9f2p/Zo3szok9su5s0nCEOevv5I1JLIpwhzJmQzrXjUvj7xwf549p9zF68nlmje3PXlYPpnxxtdYhKqU7KL6qgZ4z/FuloJMZ4rem7XTIzM01WVla7X9cYbzC2UZ+urGHZuhyWrT9AVW09N2Wm8aPLB/n9L75Synu+sWwjFdV1vDZ/slfOJyKbjDGZbZWzXdeNYEzqjWIjnPx0+hC+NSmDP36wjxc+Ocirm/MYmBxNWkI30rpHktq9G2kJkaQlNGx3tLlIKeUfR05VWNLUqpkhACXHhPOrr43gtkv68dzHuew7Ucr+gjI+3FNAZc3ZvW8So8LoHhV25hPNmc9h5sttZ4gwZVAy145L6VAzllKqY+rrDfnFlVw1opffr63JPYClJUTywKzhZ54bY3CVVnP4VDmHT5aTd6qCwyfLKa6oQQQEOdMpVWj4lCNAUUUNz36cy7L1BxjYI5prx/bhmrEppCVEWlEtpbqMwrJqqmvr/d5TBjS524qIkBwTTnJMOOPTu7frtafKqlm1/Sj/2pLP/727h/97dw8X9O3OtWP7MGt0HxKiwnwUtVJdl1XdIEGTe5fRPSqMb1zUl29c1Je8U+WszM7nX1vy+fm/vuDXb+wgPSGy4e7ffbff+EmgsQUnrpuTn88ert00lWoHq0angib3Lim1eyTzpw5k/tSB7Dx6mpXZ+Rw6We5upzcYQ8OjcRvYllfEDU9t4H+vG8UNF6RaXQWlbOGIO7n7e14Z0OTe5Q3rHcuw3rFtlnOVVnHHi5u565VstuUV8cCs4YSF6nIASp1PflElkWEhxHVz+v3a+tupPJIUHc7zt13E/7ukH89+fJBvLNvIiZJKq8NSKqA1TvVrRQ81Te7KY6EhDn42eziPzxnL50eKmf3EejYdbHmiNqUU5Bf7fx73RprcVbtdMzaF1+dPbpg+YenHPL/xIFaNdFYqkOUXVZBiwZepoMldddCw3rGsvGMyFw9I4mcrtrNw+TYqa+qsDkupgFFZU4ertNrvU/020uSuOiw+Moy/fOdCFkwbyCub8rj+TxvYd6LU6rCUCghHi93zuGuzjLKjEIdw1/QhLLs1k6PFFXx18Xr+8dkhbaZRXZ6VA5hAk7vykiuG9+TtH01hXHo897z6OXe8uIXiihqrw1LKMlb2cQdN7sqLesVF8PfbLmLhjCGs/uIYMx//iKzck1aHpZQl8t2LdPSMC7fk+prclVeFOIT5UweyfN4kHA646c8f8/iavdS1d11DpWwuv6iC5OhwwkNDLLm+JnflE+PSu7Pqzkv52pg+PLpmDzc/vfFMG6RSXUF+UaVl7e2gyV35UEyEk8fmjOORm8bwxZFirnp0HY+v2cvpSm2LV8Evv6iClO4BntxFJFdEPheRrSJyztp4IjJVRIrdx7eKyC+8H6qyq+vHp/LWnZcycUAij67Zw6WLPmDxv/dSokleBSljDEeKKiz7MhXaN3HYZcYY13mOf2SMmd3ZgFRwykiK4ulbM9l+pJjH1uzh4ff28Mx/DvD9S/vz7YsziA7XOexU8DhZVk1VbT19LFz/WJtllF+NTIlj2bcvZOUdkxmf3p0/vLObSxa9zx8/2EdpVa3V4SnlFflF1g5gAs+TuwHeFZFNIjK3lTKTRCRbRN4WkRFeik8FqdGp8fzlOxey4vbJjEuL5w/v7ObSRe/z3o7jVoemVKcdsXgAE3ie3CcbY8YDVwO3i8iUZsc3A32NMWOAxcCKlk4iInNFJEtEsgoKCjoctAoeY9Pi+et3J/D6/ItJ6d6NBS9t5vO8YqvDUqpT8i0ewAQeJndjTL773xPA68CEZsdPG2NK3durAKeIJLVwnqXGmExjTGZycnKng1fBY1x6d/723QkkRoXz/eeyOHFa54pX9pVfVEE3Zwjxkf5fpKNRm8ldRKJEJKZxG5gObG9Wppe4Z6MXkQnu8xZ6P1wVzJKiw3n61kxOV9bw/eeydJZJZVsN87hHWLJIRyNP7tx7AutFJBv4FHjLGLNaROaJyDx3mRuB7e4yTwBzjM4cpTpgeJ9YHv36WLLzilm4fJtOQKZs6cgp6xbpaNRm/zNjTA4wpoX9S5psPwk86d3QVFd11Yhe/PdVQ/jDO7sZ3DOaO6YNsjokpdrlSFGlR2sT+5J2LlYBaf7UAew9XsL/vbuHgT1imDGyl9UhKeWRhkU6qiy/c9d+7iogiQi/u2E0Y9Pi+ck/tvJFvvagUfZwzOJFOhppclcBK8IZwtJbLyA+0sn3n83iRIn2oFGB78tFOqwbnQqa3FWA6xETwdO3ZnKqvIYf/H2T9qBRAc/qRToaaXJXAW9kShyP3DSGLYeKuP/1z7UHjQpojVMP9LJwXhnQ5K5s4upRvfnJFYN5bfMR/pl12OpwlGpVflEFyTHWLdLRSJO7so0F0wZyycAkfrnyC/YeL7E6HKVa1DCAydomGdDkrmzE4RAe+foYosNDuePFLdr+rgJSwzzu1jbJgCZ3ZTM9YiJ4+Kax7D5ewm/e3GF1OEqdxRhDflEFfeL0zl2pdvvK4GR+MKU/L3xyiFWfH7U6HKXOOFVeQ2VNvTbLKNVRd00fwpi0eO55dRuHT5ZbHY5SQNM+7prcleqQsFAHi+eMAwN3vryFmrp6q0NSKmD6uIMmd2Vj6YmR/O/1o9hyqIhH3ttjdThKceRUYIxOBU3uyua+OqYPN09IY8mH+/lor67upayVW1hGTHgoCVFhVoeiyV3Z3y9mj2BgcjQ/+Uc2BSVVVoejurADrjL6JUdZukhHI03uyva6hYXw5C3jKams4af/3Ep9vU5PoKxxwFVGRmKU1WEAmtxVkBjSK4ZffHU4H+118ed1OVaHo7qgqto6jhRV0C9Jk7tSXnXLhHRmjurFw+/uZvOhU1aHo7qYQ4XlGIMmd6W8TUT47fWj6RkbwZ0vbaG4osbqkFQXcsBVBkCGnZK7iOSKyOcislVEslo4LiLyhIjsE5FtIjLe+6Eq1ba4bk4W3zKOo8WV3P+aTg+s/KcxufezYZv7ZcaYscaYzBaOXQ0Mcj/mAk95IzilOmJ8enfunj6Etz4/ykuf6vTAyj9yC8tIiAojLtJpdSiA95plrgGeMw02AvEi0ttL51aq3X4wpT+XDkri1298we5jOj2w8r2GnjKRVodxhqfJ3QDvisgmEZnbwvEUoOktUp5731lEZK6IZIlIVkGBDjhRvuNwCI/cNJaYCCd3vLiZimqdHlj51gFXGf2Soq0O4wxPk/tkY8x4GppfbheRKc2Ot9Rj/5zGTmPMUmNMpjEmMzk5uZ2hKtU+yTHhPPb1sewrKOXBN7+wOhwVxMqrazl+uop+STa7czfG5Lv/PQG8DkxoViQPSGvyPBXI90aASnXGJYOS+OFXBvDSp4d5I1t/JJVv5LoaZiYNlJ4y4EFyF5EoEYlp3AamA9ubFVsJ3OruNTMRKDbG6ETbKiD85MrBjE+P5/7XPudQoU4PrLzvTE8ZOyV3oCewXkSygU+Bt4wxq0VknojMc5dZBeQA+4Cngfk+iVapDnCGOHh8zjhEYMHLW6iu1emBlXflFrr7uAdIN0iA0LYKGGNygDEt7F/SZNsAt3s3NKW8Jy0hkkU3jOaHL2zm4Xd3c9/MYVaHpILIAVcZPWLCiQpvM6X6jY5QVV3G1aN6c/OEdJ7+KIddx05bHY4KIg09ZQLnrh00uasu5p4ZQ4iJcPLQWzt19KrymlxN7kpZKz4yjDsvH8RHe12s3aNjLVTnFVfUUFhWrcldKat9a2JfMhIjeeitndTq2quqk3IDbMKwRprcVZcTFurgvpnD2HeilJc+07lnVOc09pTRO3elAsD04T2Z2D+BR9/bo1MDq0454CpDBNITAmd0KmhyV12UiPCzWcM5VV7Nnz7YZ3U4ysYOuMroE9eNCGeI1aGcRZO76rJGpsRxw/hU/vqfXB25qjosEHvKgCZ31cXdPX0IIQ5h0epdVoeibMgYQ44md6UCT6+4CH7wlf689flRsnJPWh2OspmTZdWUVNYGXE8Z0OSuFHOn9KdnbDi/eWsn9fU6sEl57sueMoH1ZSpocleKyLBQFl41lOzDRazUaYFVO+QUNCb3wFmko5Emd6WA68alMDIllkWrd+mqTcpjuYVlhDiE1O7drA7lHJrclaJhWb6fzRrO0eJKnlmfY3U4yiZyXeWkJ0TiDAm8VBp4ESllkYn9E7lqRE/+tHY/J05XWh2ObfztPwfIO9U1u5LmBNii2E1pcleqifuuHkZ1bT1PvL/X6lBsoaCkil+9sYNf/qvrrVFrjOFgYVlA9pQBTe5KnSUjKYqbJ6Tz8qeHz0wIpVpXUFIFwL93nWDLoVMWR+NfJ0qqKK+uo78md6XsYcHlA3GGOHj4vT1WhxLwCssakrsIPLqma33aaewpY/s7dxEJEZEtIvJmC8emikixiGx1P37h3TCV8p8eMRHcdkk/3sjOZ/uRYqvDCWiu0obkPufCNNbtKehSA8ECcd3Uptpz5/4jYOd5jn9kjBnrfjzYybiUstTcr/QnPtLJH97ZbXUoAc1VUg3AT64YTFJ0OA+/23U+7eS6yggLddAnPvC6QYKHyV1EUoFZwDLfhqNUYIiNcDJ/6gA+3FPAx/sLrQ4nYLlKqwgLdZAcE84Ppw7g45xCNux3WR2WX+S4yuibEEmIQ6wOpUWe3rk/BiwEzrdszSQRyRaRt0VkREsFRGSuiGSJSFZBgS5xpgLbrZMy6B0XwaLVu3S91VYUlFaRHB2OiPCNi9LpGRvOo+/t6RL/X7muwO0pAx4kdxGZDZwwxmw6T7HNQF9jzBhgMbCipULGmKXGmExjTGZycnKHAlbKXyKcIfz4ikFsPVzEuzuOWx1OQCosrSYxOgxo+P+6/bKBfJZ7ivX7gvvuva7ecPBkecD2lAHP7twnA18TkVzgZWCaiDzftIAx5rQxptS9vQpwikiSt4NVyt9uGJ/KgOQo/vDObup0UrFzuEqrSIoOP/P86xem0ScugoffDe679/yiCqpr6+19526Muc8Yk2qMyQDmAO8bY77ZtIyI9BIRcW9PcJ9XGyqV7YWGOPjvq4aw70Qpr27OszqcgNOQ3MPOPA8PDWHB5Q2fdj7YfcLCyHwrUNdNbarD/dxFZJ6IzHM/vRHYLiLZwBPAHBPMf7ZVl3LViF6MSY3jsff2UFmjk4o1qq83FJZWn3XnDnDjBamkJXTjkSBuez/gCrLkboxZa4yZ7d5eYoxZ4t5+0hgzwhgzxhgz0RizwRfBKmUFEeGeGUPJL67k+Y0HrQ4nYBRX1FBbb85J7s4QB3dOG8T2I6eD9ruKA64yIsNC6BET3nZhi+gIVaU8cPHAJC4dlMQfP9jH6coaq8MJCI2jUxObNMs0um5cCv2Sonj0vT1BuQBKrquMjMQo3K3RAUmTu1IeWnjVUE6V17BsnU4JDFDgHsCUHH3u3WtoiIMfXT6IXcdKeHv7MX+H5nMHAnTd1KY0uSvloVGpccwa3Ztl6w+cmTCrK2uceiCplaaJr47pw6Ae0Ty6Zk9Q9TSqqavn8KkKMgJwab2mNLkr1Q53XTmYqtp6ntQpgb9M7i3cuQOEOIQfXzGYfSdKeXNb8CxfmHeqgrp6E5BL6zWlyV2pduifHM3XL0zjxU8PcbCwa08J7CqtIsQhxHdztlrm6pG9GNorht+u2sUX+cExCdsBVykQmItiN6XJXal2+vHlgwh1OLr8pGKFpdUkRIXhOM/cKg6H8PBNYxCB6/+0gVc32X+swAFXw6pTgTobZCNN7kq1U4/YCP7fpf14c9tRsg8XWR2OZZqPTm3NiD5xvLHgEsalx3PXK9n8fMV2qmvPN01VYMt1lREbEUpC1Lm9hAKJJnelOmDulP4kRIXxu7e77qRiBaXVZ41OPZ+k6HCev+0i5k7pz983HmTO0o85VmzPdWobe8oEcjdI0OSuVIfERDi5c9pAPs4pZO2erjnDqaukqsVukK0JDXFw/8xh/PGW8ew6VsLsxev5JMd+s5QcCPDZIBtpcleqg265qC99EyNZ9PauoOrq5wljTEOzTAdGaM4a3ZsVt08mNiKUW5Z9wjPrD3Tq08/Jsmpe25zHr1Z+wYd7Cjo8aKqu3nCi5PyfJipr6sgvrgj4Pu4AoVYHoJRdhYU6uHv6EBa8tIUVW45wwwWpVofkN2XVdVTV1pPYwXbnwT1jWHHHZO7+Zza/eXMHWw6d4psT+9I/KYrkmPDzNnkYY9h9vIR/7zzB+7tOsPnQKYxp6Hr5tw259E+K4tZJfbnhglRiIlrvydNof0Epr27K4/UtRzhaXMmMEb14YNYw0hLO7Q1z6GQ5xgT2nDKNNLkr1QmzRvVm6bocHnlvD7NG9ybCGWJ1SH7hKjl/H3dPxEY4WfLNC3jqw/08/O5u3tx2FICosBD6JUfRLymafklR9E+Kol9SFCfLq3nfndCPFFUAMColjjunDeLyYT0Y3DOGt7cf5dkNB/nVGzv4wzu7ueGCVG6dlMHAHmf3SS8ur2Hltnxe3ZTH1sNFOASmDE7mq2P68PePD/L+7hN8/9J+zJ86kKjwL9OkHSYMa6TJXalOcDiE+64eyi3LPuG5j3OZO2WA1SH5RVujUz3lcAi3XzaQGy9IZfexEg64ys48sg8X8da2fJq2snRzhnDJoCQWTBvIZUN70DM24qzzXTculevGpZJ9uIhnN+Ty8qeHee7jg1w6KIlbJ2UQ4oBXNx3hvR3Hqa6rZ0jPGO6fOZRrx6bQw32u703ux6LVu/jjB/t5JSuPe69uOO5wCLnu5G6HNnex6pv+zMxMk5WVZcm1lfK2b//lU7YeLmLdf19GXGTbTQF2t3r7UeY9v5m37ryEEX3ifHadqto6Dp8sJ6egjHBnCBf1S2jXpyNXaRUvf3qI5zce4tjphvb07pFOrhmbwo0XpDKiT2yrTUCbDp7iwTe+IDuvmLFp8fzyq8P5x2eHeW/HcTb9/Eqv1K8jRGSTMSazrXJ6566UF9x79VBmPvERf1q7j/tmDrM6HJ8rKG190jBvCg8NYWCPGAb2iOnQ65Oiw7lj2iB+8JUBfLDrBCLCVwYnExbadl+SC/p25/X5k3ltyxEWrd7FdX/aQFRYCMN6x3YoFn/T3jJKecGw3rFcNy6Fv27IPdMeHMwK3c0y3QN8IE8jZ4iD6SN6ceXwnh4l9kYOh3DjBal8cPdUfjh1ADV1hpEpvvuk4k2a3JXykrumDwHgkXf3WByJ77lKq+ge6cQZ0jVSSHR4KPfMGMpnD1zBvVcPtTocj3SNd0YpP0iJ78Z3Ls7gtS157Dx62upwfMpVcu7yel1BXKTTNj2iPE7uIhIiIltE5M0WjomIPCEi+0Rkm4iM926YStnD/KkDiAkPZdHqXVaH4lOeziujrNOeO/cfATtbOXY1MMj9mAs81cm4lLKl+Mgw5l82kLW7C3h/V3CuHwoNyb2l5fVU4PAouYtIKjALWNZKkWuA50yDjUC8iPT2UoxK2cp3Ls5gaK8YFi7fFrQrNhWWds1mGTvx9M79MWAh0No8nSnA4SbP89z7ziIic0UkS0SyCgq65mRLKvhFOEN4fM44TlfWsnB5dtDNGllZU0dJVS3JnRzApHyrzeQuIrOBE8aYTecr1sK+c36ijTFLjTGZxpjM5OTkdoSplL0M6RXD/VcP5YPdBfx940Grw/GqL5fX02aZQObJnftk4Gsikgu8DEwTkeeblckD0po8TwWCZ9FEpTrg2xdncNmQZB56ayd7jpdYHY7XuNwDmLRZJrC1mdyNMfcZY1KNMRnAHOB9Y8w3mxVbCdzq7jUzESg2xhz1frhK2YeI8PsbxxAdHsqdL22hsqbO6pC8onHSsERN7gGtw/3cRWSeiMxzP10F5AD7gKeB+V6ITSnbS44J5w//NZpdx0qCZs3VwjJtlrGDds0tY4xZC6x1by9pst8At3szMKWCxbShPbl1Ul+eWX+ArwxOZspge3/fpM0y9qAjVJXyg/tnDmNQj2jueiWbk2XVVofTKQUlVcSEh9pmpGZXpcldKT9o7B5ZXF7DwuXbbN09sqPL6yn/0uSulJ8M7xPLwhlDWLPzOC9+esjqcDqssLS6w8vrKf/R5K6UH31vcj8uHZTEb97cwb4TpVaH0yE6r4w9aHJXyo8cDuHh/xpDN2cIP/3nVmrrWhv0HbgammX0zj3QaXJXys96xEbwP9eOYlteMU9/dMDqcNqlpq6eU+U1euduA5rclbLAzFG9mDGiF4+u2WOr5pnGnj6a3AOfJnelLCAiPHjtCLo5Q1i4PJu6env0ntF5ZexDk7tSFukRE8EvvzqczYeKeHZDrtXheEQHMNmHJnelLHTduBSmDe3B79/ZxcHCMqvDaVPjvDKa3AOfJnelLCQiPHTdSJwOB/e8uo36AG+eOdMso4OYAp4md6Us1juuGw/MGsbGnJMBP7jJVVpFhNNBVJhOPRDoNLkrFQC+fmEakwcm8ttVOzlSVGF1OK1qGJ0ajkhL6/OoQKLJXakAICL87vrRGOC+1z4P2LlnCnReGdvQ5K5UgEhLiOSeGUNZt6eAVzblWR1Oi1yl1SRrN0hb0OSuVAD51sS+TMhI4Ddv7uD46UqrwzmHzitjH5rclQogDoew6MbRVNfW88DrgdU8U19vOFlWrcndJjS5KxVg+iVFcff0IazZeYKV2YGzznxRRQ119YZEbZaxhTaTu4hEiMinIpItIl+IyK9bKDNVRIpFZKv78QvfhKtU1/C9S/oxJi2eX7+xI2BWbvpy6gG9c7cDT+7cq4BpxpgxwFhghohMbKHcRxNSGxQAAAqxSURBVMaYse7Hg16NUqkuJsQh/P6G0ZRU1vDgG19YHQ6go1Ptps3kbho0TlvndD8CpyFQqSA1pFcM86cOZMXWfN7fddzqcChw37kn61zutuBRm7uIhIjIVuAE8J4x5pMWik1yN928LSIjWjnPXBHJEpGsgoKCToStVNdw+2UDGdwzmvtf205JZY2lseikYfbiUXI3xtQZY8YCqcAEERnZrMhmoK+76WYxsKKV8yw1xmQaYzKTk5M7E7dSXUJYqIPf3ziGEyWV/O7tXZbGUlhaRahDiI1wWhqH8ky7essYY4qAtcCMZvtPNzbdGGNWAU4RSfJWkEp1ZWPT4vne5H688MkhNuYUWhaHq7SKxOgwHA6desAOPOktkywi8e7tbsAVwK5mZXqJe7IJEZngPq91P4VKBZmfTh9MekIk9766jcqaOkticJVqH3c78eTOvTfwgYhsAz6joc39TRGZJyLz3GVuBLaLSDbwBDDHBNLoC6VsLjIslN9dP4rcwnIeXbPHkhh0dKq9hLZVwBizDRjXwv4lTbafBJ70bmhKqaYuHpjEnAvTeHpdDrNG9WZ0arxfr+8qqWJgj2i/XlN1nI5QVcpG7ps5jOSYcBYu30ZNXb3frmuMwVVWTbLeuduGJnelbCSum5P/uXYUu46VsGTtfr9dt6Sqluraem2WsRFN7krZzJXDezJ7dG8Wv7+PvcdL/HLNM6NTdQCTbWhyV8qGfvW1EUSFh/CTf26lqtb3vWd0AJP9aHJXyoaSosNZdMNoth85zaK3d/v8eo2ThiVGaXK3C03uStnU9BG9+M7FGfzlPwdYs8O3c88UlmqzjN1oclfKxu6bOZQRfWK5e3k2R4t9t7B2QWk1IpAQqcndLjS5K2Vj4aEhLL55HNW19fzopa3U+qh7pKu0ioTIMEJDNGXYhb5TStlc/+RoHrpuJJ/mnuSJ9/f55BquEh2dajea3JUKAteNS+WG8aksfn8vG/a7vH7+xknDlH1oclcqSDx4zQj6JUXx45e3nvkC1FsKdWFs29HkrlSQiAoP5cmbx1NUUcNdr2RTX++9ufu0WcZ+NLkrFUSG94nl57OGsXZ3Ac+sP+CVc1ZU11FWXafdIG1Gk7tSQeabE/ty1YieLFq9i62Hizp9vsYBTHrnbi+a3JUKMiLC728YQ8/YCBa8tJmi8upOna/gTHLXO3c70eSuVBCKi3Sy+JZxHC+uYv4Lmzs1PXChzitjS5rclQpS49O787/Xj2LD/kIefGNHh8+jzTL21OZKTEop+7rxglT2Hi/hz+tyGNwzmm9Nymj3ORqn+9V+7vbiyQLZESLyqYhki8gXIvLrFsqIiDwhIvtEZJuIjPdNuEqp9lo4YyiXD+3Br97YwX/2tX+Ak6u0itiIUMJDQ3wQnfIVT5plqoBpxpgxwFhghohMbFbmamCQ+zEXeMqrUSqlOizEITw2ZywDkqOY/8JmDrjK2vV6V6kOYLKjNpO7aVDqfup0P5qPjrgGeM5ddiMQLyK9vRuqUqqjYiKcLLv1QhwCtz37GcUVNR6/1lWqA5jsyKMvVEUkRES2AieA94wxnzQrkgIcbvI8z71PKRUg0hMjWfLNCzhUWM6Cl7Z4PIOkq7RKBzDZkEfJ3RhTZ4wZC6QCE0RkZLMi0tLLmu8QkbkikiUiWQUFBe2PVinVKRf1T+R/rh3Juj0FPLRqp0ev0WYZe2pXV0hjTBGwFpjR7FAekNbkeSqQ38LrlxpjMo0xmcnJye0MVSnlDXMmpPPdyRn89T+5vPTpofOWra6tp7iiRpO7DXnSWyZZROLd292AK4BdzYqtBG5195qZCBQbY456PVqllFc8MHMYUwYn8/MV21m+Ka/VJprCMu0GaVee3Ln3Bj4QkW3AZzS0ub8pIvNEZJ67zCogB9gHPA3M90m0SimvCA1xsPjmcQzrHcvdr2Qz7eEPeX7jQSpr6s4qp6NT7avNQUzGmG3AuBb2L2mybYDbvRuaUsqX4ro5+dftk1mz8zh/Wrufn63YzmNr9vK9SzL45sS+xEY4m8wro8ndbnSEqlJdmMMhTB/RiyuH92Rjzkme+nA/v1+9m6c+2M83JvYlrpsTgGRN7rajyV0phYgwaUAikwYksv1IMU99uJ8/r9uPcfd5066Q9qPJXSl1lpEpcfzxlvEccJWxdN1+SipriQzTVGE3+o4ppVrULymK314/2uowVAfplL9KKRWENLkrpVQQ0uSulFJBSJO7UkoFIU3uSikVhDS5K6VUENLkrpRSQUiTu1JKBSEx5pw1NfxzYZEC4GCTXXFAsYfbSUD7V/pt+VodKdPSseb77FKf9tal+fNgrU/TfZ2pj79/1po/t3t9AvlnrbVjvq5PX2NM2wtiGGMC4gEs9XQbyPLWtTpSpqVjzffZpT7trUtXqU+zfR2uj79/1oKtPoH8sxaI9Wn6CKRmmTfaue2ta3WkTEvHmu+zS33aW5fmz4O1PoFQl9aOdaX6BPLPWmvHrKzPGZY1y3SGiGQZYzKtjsNbtD6BTesTuIKpLuDd+gTSnXt7LLU6AC/T+gQ2rU/gCqa6gBfrY8s7d6WUUudn1zt3pZRS56HJXSmlgpAmd6WUCkJBl9xF5FIRWSIiy0Rkg9XxdJaIOETkIRFZLCLftjqezhKRqSLykfs9mmp1PJ0lIlEisklEZlsdS2eJyDD3+7JcRH5odTydJSLXisjTIvIvEZludTydJSL9ReQZEVnuSfmASu4i8hcROSEi25vtnyEiu0Vkn4jce75zGGM+MsbMA94EnvVlvG3xRn2Aa4AUoAbI81WsnvBSfQxQCkRgYX28VBeAe4B/+iZKz3npd2en+3fnJsDS7oVeqs8KY8z3ge8AX/dhuG3yUn1yjDG3eXxRb42G8sYDmAKMB7Y32RcC7Af6A2FANjAcGEVDAm/66NHkdf8EYu1eH+Be4Afu1y4Pgvo43K/rCbxg87pcAcyhIXnMtvt7437N14ANwC3BUB/36x4GxgdRfTzKAwG1QLYxZp2IZDTbPQHYZ4zJARCRl4FrjDG/BVr8KCwi6UCxMea0D8NtkzfqIyJ5QLX7aZ3vom2bt94ft1NAuC/i9ISX3pvLgCgafiErRGSVMabep4G3wlvvjTFmJbBSRN4CXvRdxOfnpfdHgN8BbxtjNvs24vPz8u+ORwIqubciBTjc5HkecFEbr7kN+KvPIuqc9tbnNWCxiFwKrPNlYB3UrvqIyPXAVUA88KRvQ2u3dtXFGPMAgIh8B3BZldjPo73vzVTgehr+6K7yaWQd097fnQU0fLqKE5GBxpglvgyuA9r7/iQCDwHjROQ+9x+BVtkhuUsL+8478soY80sfxeIN7aqPMaachj9Wgaq99XmNhj9YgajdP2sAxpi/eT8Ur2jve7MWWOurYLygvfV5AnjCd+F0WnvrUwjM8/TkAfWFaivygLQmz1OBfIti8QatT+AKprqA1ifQ+bQ+dkjunwGDRKSfiITR8AXWSotj6gytT+AKprqA1ifQ+bY+Vn6D3MI3yi8BR/my299t7v0zgT00fLP8gNVxan3sX59gqovWJ/AfVtRHJw5TSqkgZIdmGaWUUu2kyV0ppYKQJnellApCmtyVUioIaXJXSqkgpMldKaWCkCZ3pZQKQprclVIqCGlyV0qpIPT/AUzo2C5V3sL1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs[:len(loss2)], loss2)\n",
    "plt.xscale(\"log\")\n",
    "print(lrs[np.argmin(loss)])\n",
    "print(lrs[np.argmin(loss)] / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43922395"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model(2)\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
